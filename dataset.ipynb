{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class ImageWoof(ImageFolder):\n",
    "    \"\"\"\n",
    "    Dataset class for ImageWoof dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    DATASET_URL = \"https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2-160.tgz\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        img_size: int,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        loader=default_loader,\n",
    "        is_valid_file=None,\n",
    "        train=True,\n",
    "    ):\n",
    "        if os.path.exists(os.path.join(root, \"imagewoof2-160\")):\n",
    "            root = os.path.join(root, \"imagewoof2-160\")\n",
    "        elif os.path.exists(os.path.join(root, \"imagewoof2-160.tgz\")):\n",
    "            os.system(f\"tar zxvf {os.path.join(root, 'imagewoof2-160.tgz')}\")\n",
    "            root = os.path.join(root, \"imagewoof2-160\")\n",
    "        else:\n",
    "            download_url(self.DATASET_URL, \".\")\n",
    "            os.system(f\"tar zxvf {os.path.join(root, 'imagewoof2-160.tgz')}\")\n",
    "            root = os.path.join(root, \"imagewoof2-160\")\n",
    "\n",
    "        if train:\n",
    "            root = os.path.join(root, \"train\")\n",
    "        else:\n",
    "            root = os.path.join(root, \"val\")\n",
    "\n",
    "        if transform is None:\n",
    "            transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize((img_size, img_size)),\n",
    "                    transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        super().__init__(root, transform, target_transform, loader, is_valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def START_seed():\n",
    "    seed = 9\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--data_directory', action='store',\n",
    "                    default = '/home/dawlat.akaila/Documents/CV_LABS/assign03/',\n",
    "                    help='Set directory to load training data, e.g., \"imagewoof\"')\n",
    "parser.add_argument('--weights', action='store',\n",
    "                    default = '/home/dawlat.akaila/Documents/CV_LABS/assign03/best.pts',\n",
    "                    help='If weight available load to initialize model')\n",
    "parser.add_argument('--save_path', action='store',\n",
    "                    default = '/home/dawlat.akaila/Documents/CV_LABS/assign03/',\n",
    "                    help='Path to save weights after training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_results = parser.parse_args()\n",
    "\n",
    "data_dir = parse_results.data_directory\n",
    "weights = parse_results.weights\n",
    "save_path = parse_results.save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "START_seed()\n",
    "train_dataset = ImageWoof(root=data_dir, img_size=IMG_SIZE, train=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers = 8)\n",
    "val_dataset = ImageWoof(root=data_dir, img_size=IMG_SIZE, train=False)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, num_workers = 8)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
